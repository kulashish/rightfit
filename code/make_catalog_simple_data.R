source('spark_init.R')
catalog.simple <- parquetFile(sqlContext, '/data/input/bob1/catalog_simple/full/2015/12/20/*')
catalog.simple <- select(catalog.simple, "id_catalog_simple", "fk_catalog_config", "sku")
catalog.config <- parquetFile(sqlContext, '/data/input/bob1/catalog_config/full/2015/12/20/*')
catalog.config <- select(catalog.config, "id_catalog_config", "name", "fk_catalog_brand", "fk_catalog_attribute_set")
catalog.config <- withColumnRenamed(catalog.config, 'name', 'catalog_config_name')
catalog.simple.data <- join(catalog.simple, catalog.config, catalog.simple$fk_catalog_config==catalog.config$id_catalog_config)
catalog.attribute.set <- parquetFile(sqlContext, '/data/input/bob1/catalog_attribute_set/full/2015/12/20/*')
catalog.attribute.set <- select(catalog.attribute.set, "id_catalog_attribute_set", "name")
catalog.attribute.set <- withColumnRenamed(catalog.attribute.set, 'name', 'attribute_set_name')
catalog.simple.data <- join(catalog.simple.data, catalog.attribute.set, catalog.simple.data$fk_catalog_attribute_set==catalog.attribute.set$id_catalog_attribute_set)
catalog.simple.data <- select(catalog.simple.data, "id_catalog_simple", "sku", "id_catalog_config", "catalog_config_name", "fk_catalog_brand", "id_catalog_attribute_set", "attribute_set_name")
write.df(catalog.simple.data, '/data/input/bob1/catalog_simple_data', source='json', mode='overwrite')
